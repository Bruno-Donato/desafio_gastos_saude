{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos para Previsão de Gastos em Saúde\n",
    "\n",
    "Na primeira parte desse estudo seguimos os critérios do desafio proposto no [FreeCodeCamp](https://www.freecodecamp.org/learn/machine-learning-with-python/machine-learning-with-python-projects/linear-regression-health-costs-calculator).\n",
    "\n",
    "Nesse notebook vamos estudar outros modelos de previsão para prever os gastos em saúde"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Importando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn import metrics\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestRegressor, GradientBoostingRegressor\n",
    ")\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.linear_model import (\n",
    "    LassoCV, RidgeCV, ElasticNetCV, SGDRegressor\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler, OneHotEncoder\n",
    ")\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Formatting Table Outputs\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.Importando dataset e informações gerais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/gastos_saude.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.Pré-processamento"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['bmi', 'age', 'smoker']]\n",
    "Y = df['expenses']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, Y, test_size=0.33, random_state=42\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformações e encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "numericas = X_train.select_dtypes('number').columns\n",
    "categoricas = X_train.select_dtypes('object').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "processador_num = Pipeline([('s_scaler', StandardScaler())])\n",
    "\n",
    "processador_cat = Pipeline([('ohe', OneHotEncoder(drop=\"if_binary\"))])\n",
    "\n",
    "preprocessador = ColumnTransformer(transformers = [\n",
    "    (\"processador_num_1\", processador_num, numericas),\n",
    "    (\"processador_cat_1\", processador_cat, categoricas),\n",
    "    ], remainder='passthrough', verbose_feature_names_out=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_preproc = pd.DataFrame(\n",
    "    preprocessador.fit_transform(X_train),\n",
    "    columns = preprocessador.get_feature_names_out()\n",
    ")\n",
    "\n",
    "X_test_preproc = pd.DataFrame(\n",
    "    preprocessador.transform(X_test),\n",
    "    columns = preprocessador.get_feature_names_out()\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.Modelagem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui vamos utilizar diversos modelos para prever os gastos, e para facilitar nosso trabalho vamos criar uma função que itera pelos itens de um dicionário, armazena os dados obtidos e cria um dataframe para analisarmos as métricas obtidas de cada modelo.\n",
    "\n",
    "Temos diversas opções para modelagem, e dentre elas vamos usar:\n",
    "- __Ridge__: o objetivo é minimizar o erro quadrático somado a uma penalização da soma dos coeficientes ao quadrado. Isso ajuda a evitar overfitting e reduzir a influência de coeficientes menos relevantes.\n",
    "\n",
    "- __Lasso__: o objetivo é minimizar o erro quadrático somado a uma penalização da soma dos valores absolutos dos coeficientes. Isso ajuda a evitar overfitting e a selecionar automaticamente as variáveis mais relevantes.\n",
    "\n",
    "- __Elastic Net__: aqui combinamos a penalização de Ridge e Lasso em uma única regressão, com um parâmetro de mistura que controla o grau de ambas as penalizações. Isso ajuda a lidar com problemas em que há multicolinearidade e muitas variáveis irrelevantes.\n",
    "\n",
    "- __Gradiente Descendente__: aqui queremos minimizar a função de perda (como o erro quadrático) usando o método de gradiente descendente, que ajusta os coeficientes iterativamente para minimizar a função de perda. A versão estocástica usa amostras aleatórias do conjunto de treinamento para atualizar os coeficientes, o que torna o processo mais rápido e escalável para conjuntos de dados grandes.\n",
    "\n",
    "- __Decision Tree Regressor__: dividimos recursivamente os dados em subconjuntos com base em variáveis e valores de corte que maximizam a pureza dos subconjuntos em relação à variável de destino. Isso cria uma estrutura de árvore de decisão que pode ser usada para prever a variável de destino para novos dados.\n",
    "\n",
    "- __Random Forest Regressor__: nesse caso criamos um conjunto de árvores de decisão usando amostras aleatórias do conjunto de treinamento e variáveis aleatórias para dividir os nós da árvore. Isso ajuda a reduzir a variância e o overfitting em comparação com uma única árvore de decisão.\n",
    "\n",
    "- __Gradient Boosting Regressor__: nesse modelo é criado conjunto de árvores de decisão que sejam ajustadas iterativamente aos resíduos da árvore anterior, minimizando a função de perda (como o erro quadrático). Isso ajuda a melhorar a precisão da previsão e a reduzir o overfitting.\n",
    "\n",
    "- __MultiLayer Perceptron__: este é um modelo extremamente poderoso, baseado em redes neurais, no qual o objetivo é criar uma rede neural artificial com várias camadas de neurônios interconectados, com o objetivo de prever uma variável de destino. Cada camada usa uma função de ativação para transformar a entrada em uma saída e a saída é propagada para a próxima camada. O MLP usa backpropagation para ajustar os pesos da rede para minimizar a função de perda (como o erro quadrático).\n",
    "\n",
    "- __Radial Basis Function__: outro modelo utilizando redes neurais no qual o objetivo é criar uma rede neural artificial que usa funções de base radial para transformar as entradas em uma saída. As funções de base radial são centradas em pontos específicos no espaço de entrada e usam a distância Euclidiana entre os pontos de entrada e o centro para determinar a saída da função. A rede usa backpropagation para ajustar os pesos da rede para minimizar a função de perda (como o erro quadrático)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando dicionário\n",
    "dic_modelos = {\n",
    "    'RidgeCV Regression':RidgeCV(cv=5, \n",
    "                                 alphas=[0.001, 0.01, 0.1, 1, 10, 100]),\n",
    "    'LassoCV Regression':LassoCV(random_state=42), \n",
    "    'Elastic Net':ElasticNetCV(random_state=42),\n",
    "    'Gradiente Descendente':SGDRegressor(random_state=42),\n",
    "    'Decision Tree Regressor':DecisionTreeRegressor(max_depth=3, \n",
    "                                                     random_state=42),\n",
    "    'Random Forest Regressor':RandomForestRegressor(max_depth=3, \n",
    "                                                     random_state=42),\n",
    "    'Gradient Boosting Regressor':GradientBoostingRegressor(random_state=42, \n",
    "                                                            learning_rate=0.05),\n",
    "    'MultiLayer Perceptron':MLPRegressor(hidden_layer_sizes=(100, 50), \n",
    "                                         max_iter=100, learning_rate_init=0.03),\n",
    "    'Radial Basis Function':KernelRidge(kernel='rbf'),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando função para resumir modelos\n",
    "def resumo_modelos(dic, X_treino, y_treino, X_teste, y_teste):\n",
    "    lista_nome = []\n",
    "    lista_score = []\n",
    "    lista_mse = []\n",
    "    lista_mae = []\n",
    "    for nome_modelo, modelo in dic.items():\n",
    "        modelo.fit(X_treino, y_treino)\n",
    "        y_pred = modelo.predict(X_teste)\n",
    "        modelo_score = modelo.score(X_treino, y_treino).round(3)\n",
    "        modelo_mse = metrics.mean_squared_error(y_teste, y_pred).round(3)\n",
    "        modelo_mae = metrics.mean_absolute_error(y_teste, y_pred).round(3)\n",
    "        lista_nome.append(nome_modelo)\n",
    "        lista_score.append(modelo_score)\n",
    "        lista_mse.append(modelo_mse)\n",
    "        lista_mae.append(modelo_mae)\n",
    "    resumo_modelos = pd.DataFrame({'Modelo':lista_nome, 'R² Score':lista_score,\n",
    "                                   'MSE':lista_mse, 'MAE':lista_mae})\n",
    "    resumo_modelos.sort_values(by='R² Score', ascending=False, inplace=True, ignore_index=True)\n",
    "    return resumo_modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modelos = resumo_modelos(dic_modelos, X_train_preproc, y_train, X_test_preproc, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>R² Score</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient Boosting Regressor</td>\n",
       "      <td>0.873</td>\n",
       "      <td>22162121.230</td>\n",
       "      <td>2565.615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Regressor</td>\n",
       "      <td>0.855</td>\n",
       "      <td>22562601.276</td>\n",
       "      <td>2731.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree Regressor</td>\n",
       "      <td>0.848</td>\n",
       "      <td>24462234.426</td>\n",
       "      <td>2970.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Radial Basis Function</td>\n",
       "      <td>0.836</td>\n",
       "      <td>28058095.089</td>\n",
       "      <td>2987.111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MultiLayer Perceptron</td>\n",
       "      <td>0.819</td>\n",
       "      <td>26214369.939</td>\n",
       "      <td>2930.532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RidgeCV Regression</td>\n",
       "      <td>0.730</td>\n",
       "      <td>39401832.308</td>\n",
       "      <td>4256.858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LassoCV Regression</td>\n",
       "      <td>0.730</td>\n",
       "      <td>39281490.177</td>\n",
       "      <td>4244.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gradiente Descendente</td>\n",
       "      <td>0.730</td>\n",
       "      <td>39319921.954</td>\n",
       "      <td>4252.444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Elastic Net</td>\n",
       "      <td>0.092</td>\n",
       "      <td>154786308.480</td>\n",
       "      <td>9057.894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Modelo  R² Score           MSE      MAE\n",
       "0  Gradient Boosting Regressor     0.873  22162121.230 2565.615\n",
       "1      Random Forest Regressor     0.855  22562601.276 2731.002\n",
       "2      Decision Tree Regressor     0.848  24462234.426 2970.526\n",
       "3        Radial Basis Function     0.836  28058095.089 2987.111\n",
       "4        MultiLayer Perceptron     0.819  26214369.939 2930.532\n",
       "5           RidgeCV Regression     0.730  39401832.308 4256.858\n",
       "6           LassoCV Regression     0.730  39281490.177 4244.300\n",
       "7        Gradiente Descendente     0.730  39319921.954 4252.444\n",
       "8                  Elastic Net     0.092 154786308.480 9057.894"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rede neural (Keras/Tensorflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns = ['expenses'])\n",
    "Y = df['expenses']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, Y, test_size=0.3, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = X_train.select_dtypes('number').columns\n",
    "cat_cols = X_train.select_dtypes(exclude = 'number').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessamento_numericas = Pipeline([\n",
    "    ('imputer',SimpleImputer(strategy='median')),\n",
    "    ('escala_features',StandardScaler())\n",
    "])\n",
    "preprocessamento_categoricas = Pipeline([\n",
    "    ('imputer',SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder',OneHotEncoder(drop='if_binary'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessador_final = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('processamento_numericas',preprocessamento_numericas,num_cols),\n",
    "        ('processamento_categoricas',preprocessamento_categoricas,cat_cols),\n",
    "        ],remainder='passthrough',verbose_feature_names_out=False\n",
    ")\n",
    "                                    \n",
    "dados_treino_prep = pd.DataFrame(\n",
    "    preprocessador_final.fit_transform(X_train),\n",
    "    columns=preprocessador_final.get_feature_names_out()\n",
    ")\n",
    "\n",
    "dados_teste_prep = pd.DataFrame(\n",
    "    preprocessador_final.fit_transform(X_test),\n",
    "    columns=preprocessador_final.get_feature_names_out()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = np.array(dados_treino_prep).astype('float32')\n",
    "train_labels = np.array(y_train).astype('float32')\n",
    "\n",
    "test_samples = np.array(dados_teste_prep).astype('float32')\n",
    "test_labels = np.array(y_test).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(units=16, input_shape=(9,), activation='relu'),\n",
    "    Dense(units=32, activation='relu'),\n",
    "    Dense(units=1, activation='linear')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.05), \n",
    "              loss='mean_squared_error', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "85/85 [==============================] - 2s 7ms/step - loss: 184271456.0000 - mae: 9485.4033 - val_loss: 78762696.0000 - val_mae: 5774.5088\n",
      "Epoch 2/50\n",
      "85/85 [==============================] - 0s 4ms/step - loss: 54118428.0000 - mae: 5660.7563 - val_loss: 39965780.0000 - val_mae: 4613.0840\n",
      "Epoch 3/50\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 37889636.0000 - mae: 4250.9170 - val_loss: 34548548.0000 - val_mae: 3825.1121\n",
      "Epoch 4/50\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 35957296.0000 - mae: 4063.5164 - val_loss: 35018632.0000 - val_mae: 4310.6973\n",
      "Epoch 5/50\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 35362336.0000 - mae: 4249.4146 - val_loss: 32003402.0000 - val_mae: 3648.7837\n",
      "Epoch 6/50\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 32892522.0000 - mae: 3763.2825 - val_loss: 31405656.0000 - val_mae: 4115.0015\n",
      "Epoch 7/50\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 32863364.0000 - mae: 3824.3621 - val_loss: 28128738.0000 - val_mae: 3344.8577\n",
      "Epoch 8/50\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 31494898.0000 - mae: 3665.6589 - val_loss: 28197698.0000 - val_mae: 3507.0476\n",
      "Epoch 9/50\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 30929822.0000 - mae: 3562.5083 - val_loss: 28451228.0000 - val_mae: 3183.8352\n",
      "Epoch 10/50\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 29601930.0000 - mae: 3562.3906 - val_loss: 27729568.0000 - val_mae: 2998.1545\n",
      "Epoch 11/50\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 27712632.0000 - mae: 3233.6958 - val_loss: 25310440.0000 - val_mae: 2850.5632\n",
      "Epoch 12/50\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 27411754.0000 - mae: 3205.5208 - val_loss: 25183240.0000 - val_mae: 2796.7939\n",
      "Epoch 13/50\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 27131508.0000 - mae: 3176.6624 - val_loss: 23348132.0000 - val_mae: 2890.9109\n",
      "Epoch 14/50\n",
      "85/85 [==============================] - 0s 4ms/step - loss: 25545286.0000 - mae: 3134.9329 - val_loss: 25146132.0000 - val_mae: 2874.3171\n",
      "Epoch 15/50\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 24940222.0000 - mae: 3161.4109 - val_loss: 24968172.0000 - val_mae: 2806.1350\n",
      "Epoch 16/50\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 24341700.0000 - mae: 3123.6477 - val_loss: 23951344.0000 - val_mae: 3130.8218\n",
      "Epoch 17/50\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 24462260.0000 - mae: 2973.5552 - val_loss: 21166820.0000 - val_mae: 2617.9731\n",
      "Epoch 18/50\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 23979162.0000 - mae: 2949.0381 - val_loss: 23800328.0000 - val_mae: 2406.8423\n",
      "Epoch 19/50\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 23922050.0000 - mae: 2946.0054 - val_loss: 22521154.0000 - val_mae: 2786.2710\n",
      "Epoch 20/50\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 23475306.0000 - mae: 2901.2522 - val_loss: 22066190.0000 - val_mae: 3042.8894\n",
      "Epoch 21/50\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 23898134.0000 - mae: 2940.5659 - val_loss: 23128892.0000 - val_mae: 2731.6565\n",
      "Epoch 22/50\n",
      "85/85 [==============================] - 0s 5ms/step - loss: 23648170.0000 - mae: 3002.6895 - val_loss: 23065120.0000 - val_mae: 2821.6216\n",
      "Epoch 23/50\n",
      "85/85 [==============================] - 0s 4ms/step - loss: 23675670.0000 - mae: 2954.8945 - val_loss: 21610014.0000 - val_mae: 2891.4761\n",
      "Epoch 24/50\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 23001896.0000 - mae: 2828.3125 - val_loss: 21598480.0000 - val_mae: 2703.7717\n",
      "Epoch 25/50\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 23586704.0000 - mae: 2955.3196 - val_loss: 21595684.0000 - val_mae: 2565.1060\n",
      "Epoch 26/50\n",
      "85/85 [==============================] - 0s 6ms/step - loss: 23317756.0000 - mae: 2845.7859 - val_loss: 22543190.0000 - val_mae: 2776.6873\n",
      "Epoch 27/50\n",
      "85/85 [==============================] - 0s 4ms/step - loss: 23468498.0000 - mae: 2952.2090 - val_loss: 23991016.0000 - val_mae: 2529.2742\n",
      "Epoch 28/50\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 24107776.0000 - mae: 2874.3389 - val_loss: 22258470.0000 - val_mae: 2688.7305\n",
      "Epoch 29/50\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 22733380.0000 - mae: 2892.5693 - val_loss: 22510010.0000 - val_mae: 2578.6472\n",
      "Epoch 30/50\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 23181744.0000 - mae: 2843.2100 - val_loss: 22539754.0000 - val_mae: 2834.3391\n",
      "Epoch 31/50\n",
      "85/85 [==============================] - 0s 4ms/step - loss: 23651874.0000 - mae: 2990.4934 - val_loss: 22824508.0000 - val_mae: 2507.4395\n",
      "Epoch 32/50\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 23197146.0000 - mae: 2913.8843 - val_loss: 21687896.0000 - val_mae: 2666.7869\n",
      "Epoch 33/50\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 23055710.0000 - mae: 2849.1006 - val_loss: 26587062.0000 - val_mae: 2656.1816\n",
      "Epoch 34/50\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 23710914.0000 - mae: 2924.4180 - val_loss: 23752682.0000 - val_mae: 3711.9753\n",
      "Epoch 35/50\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 23071884.0000 - mae: 2923.9480 - val_loss: 22244734.0000 - val_mae: 2580.3206\n",
      "Epoch 36/50\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 22585052.0000 - mae: 2761.8958 - val_loss: 21983746.0000 - val_mae: 3257.0186\n",
      "Epoch 37/50\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 24296982.0000 - mae: 3110.4233 - val_loss: 22666106.0000 - val_mae: 2488.4092\n",
      "Epoch 38/50\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 22565020.0000 - mae: 2826.5195 - val_loss: 21572934.0000 - val_mae: 2865.8435\n",
      "Epoch 39/50\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 23389210.0000 - mae: 2943.3621 - val_loss: 21193012.0000 - val_mae: 2780.5769\n",
      "Epoch 40/50\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 23020146.0000 - mae: 2963.8782 - val_loss: 22725826.0000 - val_mae: 2513.4419\n",
      "Epoch 41/50\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 22773652.0000 - mae: 2786.8535 - val_loss: 23543274.0000 - val_mae: 2640.1091\n",
      "Epoch 42/50\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 22757328.0000 - mae: 2926.3416 - val_loss: 22177600.0000 - val_mae: 2878.5632\n",
      "Epoch 43/50\n",
      "85/85 [==============================] - 0s 3ms/step - loss: 22521668.0000 - mae: 2806.2498 - val_loss: 24202596.0000 - val_mae: 2720.0764\n",
      "Epoch 44/50\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 22832574.0000 - mae: 2924.2759 - val_loss: 21615294.0000 - val_mae: 2902.7705\n",
      "Epoch 45/50\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 23000800.0000 - mae: 2834.6411 - val_loss: 22713004.0000 - val_mae: 2488.9763\n",
      "Epoch 46/50\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 22774838.0000 - mae: 2866.8838 - val_loss: 22160374.0000 - val_mae: 2779.8125\n",
      "Epoch 47/50\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 22841458.0000 - mae: 2841.0876 - val_loss: 24108278.0000 - val_mae: 2780.8525\n",
      "Epoch 48/50\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 22573440.0000 - mae: 2881.4348 - val_loss: 21511624.0000 - val_mae: 2697.1023\n",
      "Epoch 49/50\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 22516346.0000 - mae: 2813.4561 - val_loss: 23048058.0000 - val_mae: 2744.8298\n",
      "Epoch 50/50\n",
      "85/85 [==============================] - 0s 2ms/step - loss: 23617490.0000 - mae: 2934.1152 - val_loss: 22486726.0000 - val_mae: 2557.1448\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26ec056dc00>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=train_samples, y=train_labels, \n",
    "          batch_size=10, validation_split=0.1, \n",
    "          epochs=50, shuffle=True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x=test_samples, batch_size=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 1ms/step - loss: 26081150.0000 - mae: 2679.7524\n"
     ]
    }
   ],
   "source": [
    "model_mse, model_mae = model.evaluate(x=test_samples, y=test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_score = metrics.r2_score(test_labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================================\n",
      "Redes Neurais (Keras/TensorFlow)\n",
      "==============================================\n",
      "R²: 0.848\n",
      "----------------------------------------------\n",
      "Erro quadrático médio: 26081150.0\n",
      "----------------------------------------------\n",
      "Erro absoluto médio: 2679.752\n",
      "==============================================\n"
     ]
    }
   ],
   "source": [
    "print('=' * 46)\n",
    "print('Redes Neurais (Keras/TensorFlow)')\n",
    "print('=' * 46)\n",
    "print(f'R²: {model_score.round(3)}')\n",
    "print('-' * 46)\n",
    "print(f\"Erro quadrático médio: {round(model_mse, 3)}\")\n",
    "print('-' * 46)\n",
    "print(f\"Erro absoluto médio: {round(model_mae, 3)}\")\n",
    "print('=' * 46)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.Conclusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rede_neural = pd.DataFrame({'Modelo':'Rede Neural (Keras/TF)', \n",
    "                            'R² Score':round(model_score,3), 'MSE':round(model_mse,3), \n",
    "                            'MAE':round(model_mae,3)}, index=[0])\n",
    "\n",
    "modelos_sumario = pd.concat([df_modelos, rede_neural], ignore_index=True)\n",
    "modelos_sumario = modelos_sumario.sort_values(by='MAE', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>R² Score</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient Boosting Regressor</td>\n",
       "      <td>0.873</td>\n",
       "      <td>22162121.230</td>\n",
       "      <td>2565.615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Rede Neural (Keras/TF)</td>\n",
       "      <td>0.848</td>\n",
       "      <td>26081150.000</td>\n",
       "      <td>2679.752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Regressor</td>\n",
       "      <td>0.855</td>\n",
       "      <td>22562601.276</td>\n",
       "      <td>2731.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MultiLayer Perceptron</td>\n",
       "      <td>0.819</td>\n",
       "      <td>26214369.939</td>\n",
       "      <td>2930.532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree Regressor</td>\n",
       "      <td>0.848</td>\n",
       "      <td>24462234.426</td>\n",
       "      <td>2970.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Radial Basis Function</td>\n",
       "      <td>0.836</td>\n",
       "      <td>28058095.089</td>\n",
       "      <td>2987.111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LassoCV Regression</td>\n",
       "      <td>0.730</td>\n",
       "      <td>39281490.177</td>\n",
       "      <td>4244.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gradiente Descendente</td>\n",
       "      <td>0.730</td>\n",
       "      <td>39319921.954</td>\n",
       "      <td>4252.444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RidgeCV Regression</td>\n",
       "      <td>0.730</td>\n",
       "      <td>39401832.308</td>\n",
       "      <td>4256.858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Elastic Net</td>\n",
       "      <td>0.092</td>\n",
       "      <td>154786308.480</td>\n",
       "      <td>9057.894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Modelo  R² Score           MSE      MAE\n",
       "0  Gradient Boosting Regressor     0.873  22162121.230 2565.615\n",
       "9       Rede Neural (Keras/TF)     0.848  26081150.000 2679.752\n",
       "1      Random Forest Regressor     0.855  22562601.276 2731.002\n",
       "4        MultiLayer Perceptron     0.819  26214369.939 2930.532\n",
       "2      Decision Tree Regressor     0.848  24462234.426 2970.526\n",
       "3        Radial Basis Function     0.836  28058095.089 2987.111\n",
       "6           LassoCV Regression     0.730  39281490.177 4244.300\n",
       "7        Gradiente Descendente     0.730  39319921.954 4252.444\n",
       "5           RidgeCV Regression     0.730  39401832.308 4256.858\n",
       "8                  Elastic Net     0.092 154786308.480 9057.894"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelos_sumario"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conseguimos implementar modelos mais complexos e com melhores métricas para fazer a previsão de gastos, sendo o melhor deles o Gradient Boosting Regressor. Porém devemos ter cuidado pois alguns modelos podem tender mais facilmente ao overfitting e são computacionalmente mais caros e devemos analisar essas situações com os diagnósticos de modelo mostrados no primeiro notebook.\n",
    "\n",
    "Então se tivermos um modelo simples que atenda as nossas expectativas e resolva nosso problema de forma satisfatória sem sombra de dúvidas podemos utiliza-lo ganhando também em explicabilidade e agilidade."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referências"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://towardsdatascience.com/implement-gradient-descent-in-python-9b93ed7108d1\n",
    "\n",
    "- https://scikit-learn.org/stable/user_guide.html\n",
    "\n",
    "- https://www.tensorflow.org/tutorials/keras/regression?hl=pt-br"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
